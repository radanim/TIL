{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radanim/TIL/blob/master/TCN_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKoPuUXYFlQ_"
      },
      "source": [
        "### Load the Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvqRJevMGz18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6a0203-efe5-4095-bdc8-3c7602139773"
      },
      "source": [
        "!pip install keras-tcn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tcn\n",
            "  Downloading keras_tcn-3.5.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (2.9.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tcn) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfPWht1ZCoSU"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tcn import TCN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUNkUL36Fijy"
      },
      "source": [
        "### Define the max features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEIAVRBCEszU"
      },
      "source": [
        "max_features = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbXV0CnvE6LR"
      },
      "source": [
        "maxlen = 100\n",
        "batch_size = 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqC5lBXAFpMn"
      },
      "source": [
        "### Load the IMDB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Wm-VCsuE_IH"
      },
      "source": [
        "print(\"Loading Data...\")\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZiMc4a8KFuhI"
      },
      "source": [
        "### Print the shape of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgQUVECXFLvx"
      },
      "source": [
        "print(f\"X_train shape: {x_train.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {x_test.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vur0ppy0FxpO"
      },
      "source": [
        "### Pad Sequence(Samples X Time)\n",
        "* Pad Sequence added and see the shape for X "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZ9Q8iouFaAq"
      },
      "source": [
        "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
        "print(f\"X_train shape: {x_train.shape}\")\n",
        "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
        "print(f\"X_test shape: {x_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZw8xthoGaUO"
      },
      "source": [
        "* Convert target y into Numpy Array "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8mlMSpdGE1H"
      },
      "source": [
        "y_train = np.array(y_train)\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "y_test = np.array(y_test)\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-jsYB_aGh1D"
      },
      "source": [
        "### Design the TCN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rokkaoJkGPxX"
      },
      "source": [
        "i = Input(shape = (maxlen,))\n",
        "x = Embedding(max_features, 128)(i)\n",
        "x = TCN(nb_filters = 64, kernel_size=6, dilations=[1,2,4,8,16,32,64])(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1, activation = 'sigmoid')(x)\n",
        "model = Model(inputs=[i], outputs=[x])\n",
        "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEfetpDtHtIF"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q56zIcSwHLku"
      },
      "source": [
        "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = 10, validation_data = [x_test, y_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4hDj23RIIcD"
      },
      "source": [
        "result = model.evaluate(x_test, y_test)\n",
        "print(f\"Accuracy : {result[1] * 100:.2f} %\")\n",
        "print(f\"Loss : {result[0] * 100:.2f} %\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_pXfJLEINbT"
      },
      "source": [
        "from tensorflow import keras\n",
        "keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSyBk3a2KACY"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqnNi_VDOR9s"
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmhziU3pPLD5"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKXBrZqAQTk4"
      },
      "source": [
        "yhat_probs = model.predict(x_test, verbose=0)\n",
        "print(y_test)\n",
        "print(np.argmax(yhat_probs, axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wUO-WlCPxOg"
      },
      "source": [
        "# predict probabilities for test set\n",
        "yhat_probs = np.argmax(model.predict(x_test, verbose=0), axis=1)\n",
        " \n",
        "# kappa\n",
        "kappa = cohen_kappa_score(y_test, yhat_probs)\n",
        "print('Cohens kappa: %f' % kappa)\n",
        "# ROC AUC\n",
        "auc = roc_auc_score(y_test, yhat_probs)\n",
        "print('ROC AUC: %f' % auc)\n",
        "\n",
        "print(classification_report(y_test, yhat_probs))\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, yhat_probs)\n",
        "sns.heatmap(matrix, annot=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}